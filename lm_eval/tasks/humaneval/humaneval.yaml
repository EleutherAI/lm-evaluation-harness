task: humaneval
dataset_path: openai/openai_humaneval
unsafe_code: true
output_type: generate_until
test_split: test
doc_to_text: "{{prompt}}\nHere is the completed function:\n\n```python\n"
doc_to_target: "{{test}}\ncheck({{entry_point}})"
metric_list:
  - metric: !function utils.pass_at_k
    aggregation: mean
    higher_is_better: true
    k: [1, 10]
generation_kwargs:
  until:
    - "\nclass"
    - "\nif"
    - "\nprint"
    - "\n```"
    - "\n```\n\n"
    - "<|eot_id|>"
    - "</s>"
  max_gen_toks: 2048
  do_sample: true
  temperature: 0.8
  top_p: 0.95
repeats: 20
num_fewshot: 0
filter_list:
  - name: "create_test"
    filter:
      - function: "custom"
        filter_fn: !function utils.build_predictions
metadata:
  version: 1.0
