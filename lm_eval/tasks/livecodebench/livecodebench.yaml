task: livecodebench
dataset_path: livecodebench/code_generation_lite
output_type: generate_until
validation_split: test
doc_to_text: "### Question:\n{{question_content}}\n\n### Answer: (Please provide your answer in a Python code block)\n\n"
doc_to_target: !function utils.doc_to_target
process_results: !function utils.process_results
num_fewshot: 0
generation_kwargs:
  until:
  - "<|end_of_text|>"
  - "<|endoftext|>"
  - "<|im_end|>"
  # Qwen3-32B parameters from Evalscope (corrected for HuggingFace)
  do_sample: false  # Set true for sampling to use temperature/top_p/top_k
  max_new_tokens: 2048  # Reasonable limit (was max_tokens: 30000)
  # temperature: 0.6  # Sampling temperature (recommended value per Qwen report)
  # top_p: 0.95  # top-p sampling (recommended value per Qwen report)
  # top_k: 20  # top-k sampling (recommended value per Qwen report)
  # Note: 'n' parameter not supported in HuggingFace, use multiple runs instead
metric_list:
  - metric: acc
    aggregation: mean
    higher_is_better: true
metadata:
  version: 1.0
