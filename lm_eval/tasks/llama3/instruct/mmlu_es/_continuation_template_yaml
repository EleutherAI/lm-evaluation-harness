dataset_path: meta-llama/Llama-3.1-8B-Instruct-evals
dataset_name: Llama-3.1-8B-Instruct-evals__multilingual_mmlu_es__details
output_type: generate_until
test_split: latest
doc_to_text: "Given the following question and four candidate answers (A, B, C and D), choose the best answer.\nQuestion: {{input_question.strip()}}\nA. {{input_choice_list.A}}\nB. {{input_choice_list.B}}\nC. {{input_choice_list.C}}\nD. {{input_choice_list.D}}\nYour response should end with \"The best answer is [the_answer_letter]\" where the [the_answer_letter] is one of A, B, C or D."
gen_prefix: "The best answer is"
doc_to_target: "{{input_correct_responses[0]}}."
num_fewshot: 5
metric_list:
  - metric: exact_match
    aggregation: mean
    higher_is_better: true
    ignore_case: true
    ignore_punctuation: true
    regexes_to_ignore:
      - "\\$"
      - "\\.$"
generation_kwargs:
  do_sample: false
  temperature: 0
  until:
    - "."
  max_gen_toks: 10
filter_list:
  - name: strict_match
    filter:
      - function: remove_whitespace
      - function: take_first
metadata:
  version: 1.0
dataset_kwargs:
  trust_remote_code: true
