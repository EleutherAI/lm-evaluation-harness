# SwahiliBench

### Paper

Title: `AI2 Reasoning Challenge (ARC) Swahili Translation`

Abstract: ``

`The ARC_Challenge_Swahili dataset is a Swahili translation of the original ARC dataset, designed to evaluate the ability of AI systems to answer multiple-choice science questions at a grade-school level. The translation was done using a combination of machine translation and human annotation to ensure high-quality translations.`

Homepage: `https://allenai.org/data/arc`

### Citation
```
@inproceedings{arc_swahili_translation_2024,
title={AI2 Reasoning Challenge (ARC) Swahili Translation},
author={sartify LLC},
booktitle={},
year={2024},
url={},
}
```

### Groups and Tasks

#### Groups

* Not part of a group yet.

#### Tasks

* `arc_challenge_swh `: This task involves selecting the correct answer from multiple choices for given science questions translated into Swahili.

### Checklist

For adding novel benchmarks/datasets to the library:
* [x] Is the task an existing benchmark in the literature?
  * [x] Have you referenced the original paper that introduced the task?
  * [x] If yes, does the original paper provide a reference implementation? If so, have you checked against the reference implementation and documented how to run such a test?

If other tasks on this dataset are already supported:
* [x] Is the "Main" variant of this task clearly denoted?
* [x] Have you provided a short sentence in a README on what each new variant adds/evaluates?
* [x] Have you noted which, if any, published evaluation setups are matched by this variant?








