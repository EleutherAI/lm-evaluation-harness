#!/bin/bash
#PBS -P CFP01-CF-060
#PBS -j oe
#PBS -k oed
#PBS -N lm_evaluation_harness_run
#PBS -q auto
#PBS -l select=1:ngpus=4
#PBS -l walltime=56:00:00

cd $PBS_O_WORKDIR

image="/app1/common/singularity-img/hopper/pytorch/pytorch_2.3.0_cuda_12.4_ngc_24.04.sif"

module load singularity

BASE_LOG_DIR="/scratch/e1583535/multiLingual-llm-project/logs/eval/lm-evaluation-harness/xcopa_pre-translation_en/0shot/vi"

mkdir -p $BASE_LOG_DIR

OUTPUT_PATH="/scratch/e1583535/results/lm_evaluation_harness/xcopa_pre-translation-0shot/vi"

mkdir -p $OUTPUT_PATH

singularity exec -e \
--env HF_HOME=/scratch/e1583535/cache \
--env HF_DATASETS_CACHE=/scratch/e1583535/cache/datasets \
$image bash << EOF > $BASE_LOG_DIR/stdout.$PBS_JOBID.log 2> $BASE_LOG_DIR/stderr.$PBS_JOBID.log

if [ -d "/hpctmp/e1583535/virtualenvs/sea-helm" ]; then
    source /hpctmp/e1583535/virtualenvs/sea-helm/bin/activate
fi

echo "Starting evaluating at $(date)"
echo "Running on host: $(hostname)"
echo "GPU info:"
nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader,nounits || echo "No GPU detected"

# Remember use limit=100 for abstract summarization task to avoid OOM

lm_eval --model hf \
--model_args pretrained=/scratch/e1583535/llm/nus-olmo/para-only-7B-34B-checkpoints/step8290-unsharded-hf,parallelize=True \
--tasks xcopa_7b-0shot_vi_en \
--output_path $OUTPUT_PATH \
--batch_size 16 

EOF