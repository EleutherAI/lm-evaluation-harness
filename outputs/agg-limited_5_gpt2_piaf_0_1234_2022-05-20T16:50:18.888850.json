{"results": [{"task_name": "piaf", "prompt_name": "Given_above_context", "acc": 0.0, "fixed_answer_choice_list": null, "dataset_path": "piaf", "dataset_name": null, "subset": null, "prompt_id": "bdeaa285-287f-44de-9bff-49dbf533be89", "prompt_jinja": "{{context}}\n\nGiven the above context, {{question}} ||| {{answers.text[0]}}", "prompt_original_task": true, "comment": "", "acc_stderr": 0.0}, {"task_name": "piaf", "prompt_name": "after_reading", "acc": 0.0, "fixed_answer_choice_list": null, "dataset_path": "piaf", "dataset_name": null, "subset": null, "prompt_id": "ec70d9f8-edd5-4b8c-b18a-a5a7fb962b9a", "prompt_jinja": "After reading the following paragraph, please answer the question that follows:\n{{context}}\n{{question}} ||| {{answers.text[0]}}", "prompt_original_task": true, "comment": "", "acc_stderr": 0.0}, {"task_name": "piaf", "prompt_name": "context_follow_q", "acc": 0.0, "fixed_answer_choice_list": null, "dataset_path": "piaf", "dataset_name": null, "subset": null, "prompt_id": "723aa38b-c671-457c-96ee-bf449184f57f", "prompt_jinja": "{{title}}\n{{context}}\nQ: {{question}}\n\nA: ||| {{answers.text[0]}}", "prompt_original_task": true, "comment": "", "acc_stderr": 0.0}, {"task_name": "piaf", "prompt_name": "extract_the_answer", "acc": 0.0, "fixed_answer_choice_list": null, "dataset_path": "piaf", "dataset_name": null, "subset": null, "prompt_id": "4bac0d14-ac52-442c-9364-ea7add071af4", "prompt_jinja": "Extract from the passage the answer to this question: {{question}}\nPassage about {{title}}: {{context}} ||| {{answers['text'][0]}}", "prompt_original_task": true, "comment": "", "acc_stderr": 0.0}, {"task_name": "piaf", "prompt_name": "given_passage_answer", "acc": 0.0, "fixed_answer_choice_list": null, "dataset_path": "piaf", "dataset_name": null, "subset": null, "prompt_id": "9f4bf5cd-070c-46a1-9098-2ad1ef63d806", "prompt_jinja": "Given the following passage answer the question that follows: \n{{context}}\n{{question}} ||| {{answers.text[0]}}", "prompt_original_task": true, "comment": "", "acc_stderr": 0.0}], "config": {"model": "hf-causal", "model_args": "pretrained=gpt2", "num_fewshot": 0, "batch_size": null, "device": "cpu", "no_cache": false, "limit": 5, "bootstrap_iters": 100000, "description_dict": {}}}